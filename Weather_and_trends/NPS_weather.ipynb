{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ParkName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>ParkType</th>\n",
       "      <th>Region</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RecreationVisits</th>\n",
       "      <th>NonRecreationVisits</th>\n",
       "      <th>...</th>\n",
       "      <th>RecreationHoursTotal</th>\n",
       "      <th>NonRecreationHoursTotal</th>\n",
       "      <th>ConcessionerLodgingTotal</th>\n",
       "      <th>ConcessionerCampingTotal</th>\n",
       "      <th>TentCampersTotal</th>\n",
       "      <th>RVCampersTotal</th>\n",
       "      <th>BackcountryTotal</th>\n",
       "      <th>NonRecreationOvernightStaysTotal</th>\n",
       "      <th>MiscellaneousOvernightStaysTotal</th>\n",
       "      <th>Google_Searches_month_prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Acadia National Park</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>National Park</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>ME</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>10810</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>10568105</td>\n",
       "      <td>47100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85815</td>\n",
       "      <td>19302</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>5378</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Acadia National Park</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>National Park</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>ME</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>11831</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>10568105</td>\n",
       "      <td>47100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85815</td>\n",
       "      <td>19302</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>5378</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Acadia National Park</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>National Park</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>ME</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>18917</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>10568105</td>\n",
       "      <td>47100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85815</td>\n",
       "      <td>19302</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>5378</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Acadia National Park</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>National Park</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>ME</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>59773</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>10568105</td>\n",
       "      <td>47100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85815</td>\n",
       "      <td>19302</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>5378</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Acadia National Park</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>National Park</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>ME</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>110330</td>\n",
       "      <td>7500</td>\n",
       "      <td>...</td>\n",
       "      <td>10568105</td>\n",
       "      <td>47100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85815</td>\n",
       "      <td>19302</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>5378</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              ParkName UnitCode       ParkType      Region State  \\\n",
       "0           0  Acadia National Park     ACAD  National Park  Northeast     ME   \n",
       "1           1  Acadia National Park     ACAD  National Park  Northeast     ME   \n",
       "2           2  Acadia National Park     ACAD  National Park  Northeast     ME   \n",
       "3           3  Acadia National Park     ACAD  National Park  Northeast     ME   \n",
       "4           4  Acadia National Park     ACAD  National Park  Northeast     ME   \n",
       "\n",
       "   Year  Month  RecreationVisits  NonRecreationVisits  ...  \\\n",
       "0  2005      1             10810                  600  ...   \n",
       "1  2005      2             11831                  600  ...   \n",
       "2  2005      3             18917                  600  ...   \n",
       "3  2005      4             59773                  600  ...   \n",
       "4  2005      5            110330                 7500  ...   \n",
       "\n",
       "   RecreationHoursTotal  NonRecreationHoursTotal  ConcessionerLodgingTotal  \\\n",
       "0              10568105                    47100                         0   \n",
       "1              10568105                    47100                         0   \n",
       "2              10568105                    47100                         0   \n",
       "3              10568105                    47100                         0   \n",
       "4              10568105                    47100                         0   \n",
       "\n",
       "   ConcessionerCampingTotal  TentCampersTotal  RVCampersTotal  \\\n",
       "0                         0             85815           19302   \n",
       "1                         0             85815           19302   \n",
       "2                         0             85815           19302   \n",
       "3                         0             85815           19302   \n",
       "4                         0             85815           19302   \n",
       "\n",
       "   BackcountryTotal  NonRecreationOvernightStaysTotal  \\\n",
       "0              1157                                 0   \n",
       "1              1157                                 0   \n",
       "2              1157                                 0   \n",
       "3              1157                                 0   \n",
       "4              1157                                 0   \n",
       "\n",
       "   MiscellaneousOvernightStaysTotal Google_Searches_month_prior  \n",
       "0                              5378                          26  \n",
       "1                              5378                          29  \n",
       "2                              5378                          42  \n",
       "3                              5378                          60  \n",
       "4                              5378                          78  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('NPS_with_trends.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_id={}\n",
    "s_id['Acadia National Park'] = ['GHCND:USC00170100','GHCND:USC00172443']\n",
    "s_id['Arches National Park'] = ['GHCND:USW00093075']\n",
    "s_id['Badlands National Park'] = ['GHCND:USC00394184']\n",
    "s_id['Big Bend National Park'] = ['GHCND:USC00416792']\n",
    "s_id['Biscayne National Park'] = ['GHCND:USC00087760']\n",
    "s_id['Black Canyon of the Gunnison National Park'] = ['GHCND:USC00050754']\n",
    "s_id['Bryce Canyon National Park'] = ['GHCND:USS0012M26S']\n",
    "s_id['Canyonlands National Park'] = ['GHCND:USC00423600']\n",
    "s_id['Capitol Reef National Park'] = ['GHCND:USC00421171']\n",
    "s_id['Carlsbad Caverns National Park'] = ['GHCND:USC00291480']\n",
    "s_id['Channel Islands National Park'] = ['GHCND:USW00093110']\n",
    "s_id['Congaree National Park'] = ['GHCND:USC00387683','GHCND:USW00053867']\n",
    "s_id['Crater Lake National Park'] = ['GHCND:USS0022G06S']\n",
    "s_id['Cuyahoga Valley National Park'] = ['GHCND:USW00014820']\n",
    "s_id['Death Valley National Park'] = ['GHCND:USC00042319']\n",
    "s_id['Denali National Park'] = ['GHCND:USS0050O01S']\n",
    "s_id['Dry Tortugas National Park'] = ['GHCND:USC00084571']\n",
    "s_id['Everglades National Park'] = ['GHCND:USC00083020']\n",
    "s_id['Gates of the Arctic National Park'] = ['GHCND:USS0050S01S']\n",
    "s_id['Gateway Arch National Park'] = ['GHCND:USC00237452']\n",
    "s_id['Glacier Bay National Park'] = ['GHCND:USC00504107']\n",
    "s_id['Glacier National Park'] = ['GHCND:USS0013A19S']\n",
    "s_id['Grand Canyon National Park'] = ['GHCND:USC00026471']\n",
    "s_id['Grand Teton National Park'] = ['GHCND:USC00486440']\n",
    "s_id['Great Basin National Park'] = ['GHCND:USC00263340']\n",
    "s_id['Great Sand Dunes National Park'] = ['GHCND:USC00053541']\n",
    "s_id['Great Smoky Mountains National Park'] = ['GHCND:USC00406328']\n",
    "s_id['Guadalupe Mountains National Park'] = ['GHCND:USC00412485','GHCND:USC00417044','GHCND:USW00023055']\n",
    "s_id['Haleakala National Park'] = ['GHCND:USC00511004']\n",
    "s_id['Hawaii Volcanoes National Park'] = ['GHCND:USC00511303','GHCND:USW00021515']\n",
    "s_id['Hot Springs National Park'] = ['GHCND:USC00033466']\n",
    "s_id['Indiana Dunes National Park'] = ['GHCND:USC00111577']\n",
    "s_id['Isle Royale National Park'] = ['GHCND:USW00094992']\n",
    "s_id['Joshua Tree National Park'] = ['GHCND:USC00049099']\n",
    "s_id['Katmai National Park'] = ['GHCND:USS0051K05S']\n",
    "s_id['Kenai Fjords National Park'] = ['GHCND:USS0051K05S']\n",
    "s_id['Kings Canyon National Park'] = ['GHCND:USC00043551']\n",
    "s_id['Kobuk Valley National Park'] = ['GHCND:USW00096407']\n",
    "s_id['Lake Clark National Park'] = ['GHCND:USC00507570']\n",
    "s_id['Lassen Volcanic National Park'] = ['GHCND:USC00045311']\n",
    "s_id['Mammoth Cave National Park'] = ['GHCND:USC00155097']\n",
    "s_id['Mesa Verde National Park'] = ['GHCND:USC00290692']\n",
    "s_id['Mount Rainier National Park'] = ['GHCND:USS0021C40S']\n",
    "s_id['National Park of American Samoa'] = ['GHCND:AQW00061705']\n",
    "s_id['New River Gorge National Park'] = ['GHCND:USW00003872']\n",
    "s_id['North Cascades National Park'] = ['GHCND:USC00455840']\n",
    "s_id['Olympic National Park'] = ['GHCND:USW00004237','GHCND:USC00456624']\n",
    "s_id['Petrified Forest National Park'] = ['GHCND:USC00026190']\n",
    "s_id['Pinnacles National Park'] = ['GHCND:USC00046926']\n",
    "s_id['Redwood National Park'] = ['GHCND:USW00024283']\n",
    "s_id['Rocky Mountain National Park'] = ['GHCND:USS0005J39S']\n",
    "s_id['Saguaro National Park'] = ['GHCND:USC00028795']\n",
    "s_id['Sequoia National Park'] = ['GHCND:USC00040343']\n",
    "s_id['Shenandoah National Park'] = ['GHCND:USC00445096']\n",
    "s_id['Theodore Roosevelt National Park'] = ['GHCND:USC00329246','GHCND:USC00323705']\n",
    "s_id['Virgin Islands National Park'] = ['GHCND:VQC00671980']\n",
    "s_id['Voyageurs National Park'] = ['GHCND:USC00214191']\n",
    "s_id['White Sands National Park'] = ['GHCND:USC00299686']\n",
    "s_id['Wind Cave National Park'] = ['GHCND:USW00094032']\n",
    "s_id['Wrangell-St. Elias National Park'] = ['GHCND:USS0042M01S','GHCND:USC00505757']\n",
    "s_id['Yellowstone National Park'] = ['GHCND:USS0010E03S']\n",
    "s_id['Yosemite National Park'] = ['GHCND:USC00049855']\n",
    "s_id['Zion National Park'] = ['GHCND:USC00429717']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2021-02-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': '3,7',\n",
       "  'value': 4.86},\n",
       " {'date': '2021-03-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': '2,7',\n",
       "  'value': 5.42},\n",
       " {'date': '2021-04-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': ',7',\n",
       "  'value': 12.33},\n",
       " {'date': '2021-08-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': ',7',\n",
       "  'value': 23.6},\n",
       " {'date': '2021-10-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': '5,7',\n",
       "  'value': 10.91},\n",
       " {'date': '2021-11-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': '3,7',\n",
       "  'value': 9.38},\n",
       " {'date': '2021-12-01T00:00:00',\n",
       "  'datatype': 'TAVG',\n",
       "  'station': 'GHCND:USC00049855',\n",
       "  'attributes': ',7',\n",
       "  'value': 2.28}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token = 'XpapSABquGPOSCjTdKfwjVJrPUAOYlFx'\n",
    "station_id = 'GHCND:USC00049855'\n",
    "year='2021'\n",
    "r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "d=json.loads(r.text)\n",
    "d['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acadia National Park\n",
      "Arches National Park\n",
      "Badlands National Park\n",
      "Big Bend National Park\n",
      "Biscayne National Park\n",
      "Black Canyon of the Gunnison National Park\n",
      "Bryce Canyon National Park\n",
      "Canyonlands National Park\n",
      "Capitol Reef National Park\n",
      "Carlsbad Caverns National Park\n",
      "Channel Islands National Park\n",
      "Congaree National Park\n",
      "Crater Lake National Park\n",
      "Cuyahoga Valley National Park\n",
      "Death Valley National Park\n",
      "Denali National Park\n",
      "Dry Tortugas National Park\n",
      "Everglades National Park\n",
      "Gates of the Arctic National Park\n",
      "Gateway Arch National Park\n",
      "Glacier Bay National Park\n",
      "Glacier National Park\n",
      "Grand Canyon National Park\n",
      "Grand Teton National Park\n",
      "Great Basin National Park\n",
      "Great Sand Dunes National Park\n",
      "Great Smoky Mountains National Park\n",
      "Guadalupe Mountains National Park\n",
      "Haleakala National Park\n",
      "Hawaii Volcanoes National Park\n",
      "Hot Springs National Park\n",
      "Indiana Dunes National Park\n",
      "Isle Royale National Park\n",
      "Joshua Tree National Park\n",
      "Katmai National Park\n",
      "Kenai Fjords National Park\n",
      "Kings Canyon National Park\n",
      "Kobuk Valley National Park\n",
      "Lake Clark National Park\n",
      "Lassen Volcanic National Park\n",
      "Mammoth Cave National Park\n",
      "Mesa Verde National Park\n",
      "Mount Rainier National Park\n",
      "National Park of American Samoa\n",
      "New River Gorge National Park\n",
      "North Cascades National Park\n",
      "Olympic National Park\n",
      "Petrified Forest National Park\n",
      "Pinnacles National Park\n",
      "Redwood National Park\n",
      "Rocky Mountain National Park\n",
      "Saguaro National Park\n",
      "Sequoia National Park\n",
      "Shenandoah National Park\n",
      "Theodore Roosevelt National Park\n",
      "Virgin Islands National Park\n",
      "Voyageurs National Park\n",
      "White Sands National Park\n",
      "Wind Cave National Park\n",
      "Wrangell-St. Elias National Park\n",
      "Yellowstone National Park\n",
      "Yosemite National Park\n",
      "Zion National Park\n"
     ]
    }
   ],
   "source": [
    "for i in s_id.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: Acadia National Park\n",
      "working on year 2021\n",
      "working on: Arches National Park\n",
      "working on year 2021\n",
      "working on: Badlands National Park\n",
      "working on year 2021\n",
      "working on: Big Bend National Park\n",
      "working on year 2021\n",
      "working on: Biscayne National Park\n",
      "working on year 2021\n",
      "working on: Black Canyon of the Gunnison National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Bryce Canyon National Park\n",
      "working on year 2021\n",
      "working on: Canyonlands National Park\n",
      "working on year 2021\n",
      "working on: Capitol Reef National Park\n",
      "working on year 2021\n",
      "working on: Carlsbad Caverns National Park\n",
      "working on year 2021\n",
      "working on: Channel Islands National Park\n",
      "working on year 2021\n",
      "working on: Congaree National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Crater Lake National Park\n",
      "working on year 2021\n",
      "working on: Cuyahoga Valley National Park\n",
      "working on year 2021\n",
      "working on: Death Valley National Park\n",
      "working on year 2021\n",
      "working on: Denali National Park\n",
      "working on year 2021\n",
      "working on: Dry Tortugas National Park\n",
      "working on year 2021\n",
      "working on: Everglades National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Gates of the Arctic National Park\n",
      "working on year 2021\n",
      "working on: Gateway Arch National Park\n",
      "working on year 2021\n",
      "working on: Glacier Bay National Park\n",
      "working on year 2021\n",
      "working on: Glacier National Park\n",
      "working on year 2021\n",
      "working on: Grand Canyon National Park\n",
      "working on year 2021\n",
      "working on: Grand Teton National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Great Basin National Park\n",
      "working on year 2021\n",
      "working on: Great Sand Dunes National Park\n",
      "working on year 2021\n",
      "working on: Great Smoky Mountains National Park\n",
      "working on year 2021\n",
      "working on: Guadalupe Mountains National Park\n",
      "working on year 2021\n",
      "working on: Haleakala National Park\n",
      "working on year 2021\n",
      "working on: Hawaii Volcanoes National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Hot Springs National Park\n",
      "working on year 2021\n",
      "working on: Indiana Dunes National Park\n",
      "working on year 2021\n",
      "working on: Isle Royale National Park\n",
      "working on year 2021\n",
      "working on: Joshua Tree National Park\n",
      "working on year 2021\n",
      "working on: Katmai National Park\n",
      "working on year 2021\n",
      "working on: Kenai Fjords National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Kings Canyon National Park\n",
      "working on year 2021\n",
      "working on: Kobuk Valley National Park\n",
      "working on year 2021\n",
      "working on: Lake Clark National Park\n",
      "working on year 2021\n",
      "working on: Lassen Volcanic National Park\n",
      "working on year 2021\n",
      "working on: Mammoth Cave National Park\n",
      "working on year 2021\n",
      "working on: Mesa Verde National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Mount Rainier National Park\n",
      "working on year 2021\n",
      "working on: National Park of American Samoa\n",
      "working on year 2021\n",
      "working on: New River Gorge National Park\n",
      "working on year 2021\n",
      "working on: North Cascades National Park\n",
      "working on year 2021\n",
      "working on: Olympic National Park\n",
      "working on year 2021\n",
      "working on: Petrified Forest National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Pinnacles National Park\n",
      "working on year 2021\n",
      "working on: Redwood National Park\n",
      "working on year 2021\n",
      "working on: Rocky Mountain National Park\n",
      "working on year 2021\n",
      "working on: Saguaro National Park\n",
      "working on year 2021\n",
      "working on: Sequoia National Park\n",
      "working on year 2021\n",
      "working on: Shenandoah National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Theodore Roosevelt National Park\n",
      "working on year 2021\n",
      "working on: Virgin Islands National Park\n",
      "working on year 2021\n",
      "working on: Voyageurs National Park\n",
      "working on year 2021\n",
      "working on: White Sands National Park\n",
      "working on year 2021\n",
      "working on: Wind Cave National Park\n",
      "working on year 2021\n",
      "working on: Wrangell-St. Elias National Park\n",
      "working on year 2021\n",
      "Failed\n",
      "working on: Yellowstone National Park\n",
      "working on year 2021\n",
      "working on: Yosemite National Park\n",
      "working on year 2021\n",
      "working on: Zion National Park\n",
      "working on year 2021\n"
     ]
    }
   ],
   "source": [
    "Token = 'XpapSABquGPOSCjTdKfwjVJrPUAOYlFx'\n",
    "station_id = 'GHCND:USS0042M01S'\n",
    "\n",
    "#initialize lists to store data\n",
    "dates_temp = []\n",
    "dates_prcp = []\n",
    "temps = []\n",
    "prcp = []\n",
    "\n",
    "for park in s_id.keys():\n",
    "    print(\"working on:\",park)\n",
    "    for year in range(2021,2022):\n",
    "        year = str(year)\n",
    "        print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "        r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "        d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "        try: \n",
    "            avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "        except:\n",
    "            print('Failed')\n",
    "            avg_temps = [{'date': str(year)+'-01-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-02-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-03-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-04-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-05-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-06-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-07-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-08-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-09-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-10-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-11-01T00:00:00','value': 100},\n",
    "            {'date': str(year)+'-12-01T00:00:00','value': 100},]\n",
    "    #get the date field from all average temperature readings\n",
    "        dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "        temps += [item['value'] for item in avg_temps]\n",
    "\n",
    "#initialize dataframe\n",
    "    df_temp = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime and convert temperature from tenths of Celsius to Fahrenheit)\n",
    "    df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "    df_temp['avgTemp'] = [float(v)*1.8 + 32 for v in temps]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GHCND:USC00049855\n"
     ]
    }
   ],
   "source": [
    "for i in s_id['Yosemite National Park']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token = 'XpapSABquGPOSCjTdKfwjVJrPUAOYlFx'\n",
    "station_id = 'GHCND:USC00049855'\n",
    "year='2021'\n",
    "r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "d=json.loads(r.text)\n",
    "len(d['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (36) does not match length of index (198)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kozto\\Desktop\\Capstone\\Michael\\NPS_weather.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kozto/Desktop/Capstone/Michael/NPS_weather.ipynb#X10sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m#get the actual average temperature from all average temperature readings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kozto/Desktop/Capstone/Michael/NPS_weather.ipynb#X10sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m         temps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [item[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m avg_temps]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Kozto/Desktop/Capstone/Michael/NPS_weather.ipynb#X10sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     df_temp[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m [datetime\u001b[39m.\u001b[39mstrptime(d, \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39mT\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dates_temp]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Kozto/Desktop/Capstone/Michael/NPS_weather.ipynb#X10sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     df_temp[park] \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(v)\u001b[39m*\u001b[39m\u001b[39m1.8\u001b[39m \u001b[39m+\u001b[39m \u001b[39m32\u001b[39m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m temps]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Kozto/Desktop/Capstone/Michael/NPS_weather.ipynb#X10sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kozto\\Desktop\\Echotrail\\env1\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\Kozto\\Desktop\\Echotrail\\env1\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\Kozto\\Desktop\\Echotrail\\env1\\lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4532\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4534\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4535\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4536\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kozto\\Desktop\\Echotrail\\env1\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (36) does not match length of index (198)"
     ]
    }
   ],
   "source": [
    "Token = 'XpapSABquGPOSCjTdKfwjVJrPUAOYlFx'\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "def my_join(row):\n",
    "    ans=row.iloc[0]\n",
    "    if abs(ans-212.0) < 0.1:\n",
    "        try:\n",
    "            ans = row.iloc[1]\n",
    "        except:\n",
    "            pass\n",
    "    if abs(ans-212.0) < 0.1:\n",
    "        try:\n",
    "            ans = row.iloc[2]\n",
    "        except:\n",
    "            pass\n",
    "    return ans\n",
    "\n",
    "for park in s_id.keys():\n",
    "    if park == 'Acadia National Park':\n",
    "        for i in range(len(s_id[park])):\n",
    "            time.sleep(0.5)\n",
    "            station_id = s_id[park][i]\n",
    "            dates_temp = []\n",
    "            dates_prcp = []\n",
    "            temps = []\n",
    "            prcp = []\n",
    "            df_park = pd.DataFrame()\n",
    "\n",
    "        #for each year from 2015-2019 ...\n",
    "        for year in range(2005, 2022):\n",
    "            time.sleep(0.5)\n",
    "            year = str(year)\n",
    "    #make the api call\n",
    "            r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "            d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "            try: \n",
    "                avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "            except:\n",
    "                avg_temps = [{'date': str(year)+'-01-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-02-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-03-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-04-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-05-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-06-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-07-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-08-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-09-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-10-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-11-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-12-01T00:00:00','value': 100},]\n",
    "    #get the date field from all average temperature readings\n",
    "            dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "            temps += [item['value'] for item in avg_temps]\n",
    "\n",
    "        df_park[i] = [float(v)*1.8 + 32 for v in temps]\n",
    "        \n",
    "        df_park[park]= df_park.apply(lambda row: my_join(row), axis=1)\n",
    "        df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "        df_temp[park]= df_park[park]\n",
    "\n",
    "    elif len(s_id[park])==1:\n",
    "        station_id = s_id[park][0]\n",
    "        dates_temp = []\n",
    "        dates_prcp = []\n",
    "        temps = []\n",
    "        prcp = []\n",
    "\n",
    "        #for each year from 2015-2019 ...\n",
    "        for year in range(2019, 2022):\n",
    "            time.sleep(0.5)\n",
    "            year = str(year)\n",
    "    #make the api call\n",
    "            r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "            d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "            try: \n",
    "             avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "            except:\n",
    "                avg_temps = [{'date': str(year)+'-01-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-02-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-03-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-04-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-05-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-06-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-07-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-08-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-09-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-10-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-11-01T00:00:00','value': 100},\n",
    "                {'date': str(year)+'-12-01T00:00:00','value': 100},]\n",
    "    #get the date field from all average temperature readings\n",
    "            dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "            temps += [item['value'] for item in avg_temps]\n",
    "\n",
    "        df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "        df_temp[park] = [float(v)*1.8 + 32 for v in temps]\n",
    "\n",
    "    else:\n",
    "        for i in range(len(s_id[park])):\n",
    "            time.sleep(0.5)\n",
    "            station_id = s_id[park][i]\n",
    "            dates_temp = []\n",
    "            dates_prcp = []\n",
    "            temps = []\n",
    "            prcp = []\n",
    "            df_park = pd.DataFrame()\n",
    "\n",
    "        #for each year from 2015-2019 ...\n",
    "            for year in range(2005, 2022):\n",
    "                time.sleep(0.5)\n",
    "                year=str(year)\n",
    "    #make the api call\n",
    "                r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "                d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "                try: \n",
    "                    avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "                except:\n",
    "                    avg_temps = [{'date': str(year)+'-01-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-02-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-03-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-04-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-05-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-06-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-07-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-08-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-09-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-10-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-11-01T00:00:00','value': 100},\n",
    "                    {'date': str(year)+'-12-01T00:00:00','value': 100},]\n",
    "    #get the date field from all average temperature readings\n",
    "                dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "                temps += [item['value'] for item in avg_temps]\n",
    "\n",
    "            df_park[i] = [float(v)*1.8 + 32 for v in temps]\n",
    "        \n",
    "        df_park[park]= df_park.apply(lambda row: my_join(row), axis=1)\n",
    "        df_temp[park]= df_park[park]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 2001\n",
      "working on year 2002\n",
      "working on year 2003\n",
      "working on year 2004\n",
      "working on year 2005\n",
      "working on year 2006\n",
      "working on year 2007\n",
      "working on year 2008\n",
      "working on year 2009\n",
      "working on year 2010\n",
      "working on year 2011\n",
      "working on year 2012\n",
      "working on year 2013\n",
      "working on year 2014\n",
      "working on year 2015\n",
      "working on year 2016\n",
      "working on year 2017\n",
      "working on year 2018\n",
      "working on year 2019\n"
     ]
    }
   ],
   "source": [
    "Token = 'XpapSABquGPOSCjTdKfwjVJrPUAOYlFx'\n",
    "station_id = 'GHCND:USS0042M01S'\n",
    "\n",
    "\n",
    "#initialize lists to store data\n",
    "dates_temp = []\n",
    "dates_prcp = []\n",
    "temps = []\n",
    "prcp = []\n",
    "\n",
    "#for each year from 2015-2019 ...\n",
    "for year in range(2001, 2020):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GSOM&datatypeid=TAVG&limit=1000&stationid='+station_id+'&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "    try: \n",
    "        avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    except:\n",
    "        avg_temps = [{'date': str(year)+'-01-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-02-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-03-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-04-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-05-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-06-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-07-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-08-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-09-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-10-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-11-01T00:00:00','value': 100},\n",
    "        {'date': str(year)+'-12-01T00:00:00','value': 100},]\n",
    "    #get the date field from all average temperature readings\n",
    "    dates_temp += [item['date'] for item in avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    temps += [item['value'] for item in avg_temps]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframe\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "#populate date and average temperature fields (cast string date to datetime and convert temperature from tenths of Celsius to Fahrenheit)\n",
    "df_temp['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "df_temp['avgTemp'] = [float(v)*1.8 + 32 for v in temps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avgTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-02-01</td>\n",
       "      <td>212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-03-01</td>\n",
       "      <td>212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>212.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>53.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>46.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>30.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>24.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  avgTemp\n",
       "0   2001-01-01  212.000\n",
       "1   2001-02-01  212.000\n",
       "2   2001-03-01  212.000\n",
       "3   2001-04-01  212.000\n",
       "4   2001-05-01  212.000\n",
       "..         ...      ...\n",
       "216 2019-08-01   53.924\n",
       "217 2019-09-01   46.544\n",
       "218 2019-10-01   30.470\n",
       "219 2019-11-01   24.242\n",
       "220 2019-12-01   10.292\n",
       "\n",
       "[221 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdd35c202359319e95c4c766d78d86c3a328e5b204d6c1e4a38058cd1bc37010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
